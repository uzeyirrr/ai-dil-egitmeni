"use client";

import { useState, useRef, useEffect } from "react";
import { Button } from "./ui/button";
import { Mic, MicOff, Phone, PhoneOff } from "lucide-react";
import { motion } from "motion/react";
import { cn } from "@/utils";

interface VoiceChatProps {
  accessToken: string;
}

export default function VoiceChat({ accessToken }: VoiceChatProps) {
  const [isConnected, setIsConnected] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [aiResponse, setAiResponse] = useState("");
  const [language, setLanguage] = useState<"en-US" | "tr-TR">("en-US");
  const [isContinuousMode, setIsContinuousMode] = useState(true);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recognitionRef = useRef<any>(null);

  const startVoiceChat = async () => {
    try {
      // Mikrofon eriÅŸimi al
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });

      // MediaRecorder baÅŸlat
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        await processAudio(audioBlob);
      };

             // Speech Recognition baÅŸlat
       if ('webkitSpeechRecognition' in window) {
         const recognition = new (window as any).webkitSpeechRecognition();
         recognition.continuous = true;
         recognition.interimResults = true;
         recognition.lang = language; // SeÃ§ilen dil

        recognition.onstart = () => {
          setIsListening(true);
        };

        recognition.onresult = (event: any) => {
          let finalTranscript = '';
          for (let i = event.resultIndex; i < event.results.length; i++) {
            if (event.results[i].isFinal) {
              finalTranscript += event.results[i][0].transcript;
            }
          }
          if (finalTranscript) {
            setTranscript(finalTranscript);
            sendMessage(finalTranscript);
          }
        };

        recognition.onerror = (event: any) => {
          console.error('Speech recognition error:', event.error);
          setIsListening(false);
        };

                 recognition.onend = () => {
           setIsListening(false);
           // SÃ¼rekli dinleme modunda otomatik olarak yeniden baÅŸlat
           if (isConnected && isContinuousMode) {
             setTimeout(() => {
               if (recognitionRef.current) {
                 recognitionRef.current.start();
               }
             }, 100);
           }
         };

        recognitionRef.current = recognition;
        recognition.start();
      }

      setIsConnected(true);
    } catch (error) {
      console.error('Error starting voice chat:', error);
      alert('Mikrofon eriÅŸimi saÄŸlanamadÄ±.');
    }
  };

  const stopVoiceChat = () => {
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
    }
    
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
    
    setIsConnected(false);
    setIsListening(false);
    setIsSpeaking(false);
  };

  const sendMessage = async (message: string) => {
    try {
      // KÄ±sa mesajlarÄ± filtrele
      if (message.trim().length < 2) return;
      
      setAiResponse(""); // YanÄ±tÄ± temizle
      
      const response = await fetch("/api/google-ai-stream", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          message,
          systemPrompt: `You are an English teacher. Respond in English and help the student improve their English skills. Keep responses very short and conversational.`
        }),
      });

      if (!response.ok) {
        throw new Error("Failed to get response");
      }

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      let fullResponse = "";

      if (reader) {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = decoder.decode(value);
          const lines = chunk.split('\n');

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              try {
                const data = JSON.parse(line.slice(6));
                if (data.text) {
                  fullResponse += data.text;
                  setAiResponse(fullResponse);
                }
                if (data.done) {
                  // Stream tamamlandÄ±, sesli yanÄ±t ver
                  speakResponse(fullResponse);
                  break;
                }
              } catch (e) {
                // JSON parse hatasÄ±, devam et
              }
            }
          }
        }
      }
    } catch (error) {
      console.error("Error sending message:", error);
      setAiResponse("ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu.");
    }
  };

  const processAudio = async (audioBlob: Blob) => {
    // Burada ses dosyasÄ±nÄ± Google AI'ya gÃ¶nderebiliriz
    // Åimdilik sadece transcript kullanÄ±yoruz
    console.log('Audio processed:', audioBlob.size, 'bytes');
  };

       const speakResponse = (text: string) => {
    if ('speechSynthesis' in window) {
      setIsSpeaking(true);
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'en-US';
      utterance.rate = 0.9; // Biraz daha hÄ±zlÄ±
      utterance.pitch = 1.1; // Biraz daha yÃ¼ksek ton
      utterance.volume = 0.9;
      
      utterance.onend = () => {
        setIsSpeaking(false);
        // AI konuÅŸmasÄ± bittikten sonra dinlemeye devam et
        if (isConnected && isContinuousMode && recognitionRef.current) {
          setTimeout(() => {
            recognitionRef.current.start();
          }, 300); // Daha hÄ±zlÄ± yeniden baÅŸlat
        }
      };
      
      speechSynthesis.speak(utterance);
    }
  };

  return (
    <div className="flex flex-col items-center justify-center min-h-screen p-4">
      <div className="max-w-md w-full space-y-6">
                           <div className="text-center">
            <h2 className="text-2xl font-bold mb-2">Sesli Ä°ngilizce Dersi</h2>
            <p className="text-muted-foreground">
              Gemini 2.0 Flash ile gerÃ§ek zamanlÄ± stream gÃ¶rÃ¼ÅŸme
            </p>
          </div>

                   {/* Dil SeÃ§imi */}
          <div className="flex justify-center gap-2">
            <Button
              onClick={() => setLanguage("en-US")}
              variant={language === "en-US" ? "default" : "outline"}
              size="sm"
            >
              ğŸ‡ºğŸ‡¸ Ä°ngilizce KonuÅŸ
            </Button>
            <Button
              onClick={() => setLanguage("tr-TR")}
              variant={language === "tr-TR" ? "default" : "outline"}
              size="sm"
            >
              ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e KonuÅŸ
            </Button>
          </div>

          {/* SÃ¼rekli Dinleme Modu */}
          <div className="flex justify-center">
            <Button
              onClick={() => setIsContinuousMode(!isContinuousMode)}
              variant={isContinuousMode ? "default" : "outline"}
              size="sm"
              className="flex items-center gap-2"
            >
              {isContinuousMode ? "ğŸ”„" : "â¸ï¸"}
              {isContinuousMode ? "SÃ¼rekli Dinleme" : "Tek Seferlik"}
            </Button>
          </div>

        {/* Durum GÃ¶stergeleri */}
        <div className="flex justify-center gap-4">
          <div className={cn(
            "flex items-center gap-2 px-3 py-2 rounded-full text-sm",
            isListening ? "bg-green-100 text-green-800" : "bg-gray-100 text-gray-600"
          )}>
            <div className={cn(
              "w-2 h-2 rounded-full",
              isListening ? "bg-green-500 animate-pulse" : "bg-gray-400"
            )} />
            {isListening ? "Dinleniyor" : "Bekliyor"}
          </div>
          
          <div className={cn(
            "flex items-center gap-2 px-3 py-2 rounded-full text-sm",
            isSpeaking ? "bg-blue-100 text-blue-800" : "bg-gray-100 text-gray-600"
          )}>
            <div className={cn(
              "w-2 h-2 rounded-full",
              isSpeaking ? "bg-blue-500 animate-pulse" : "bg-gray-400"
            )} />
            {isSpeaking ? "KonuÅŸuyor" : "Sessiz"}
          </div>
        </div>

        {/* Ana Kontrol Butonu */}
        <div className="flex justify-center">
          <Button
            onClick={isConnected ? stopVoiceChat : startVoiceChat}
            className={cn(
              "w-20 h-20 rounded-full text-lg",
              isConnected 
                ? "bg-red-500 hover:bg-red-600" 
                : "bg-green-500 hover:bg-green-600"
            )}
          >
            {isConnected ? <PhoneOff className="w-8 h-8" /> : <Phone className="w-8 h-8" />}
          </Button>
        </div>

        {/* Transcript */}
        {transcript && (
          <motion.div
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            className="bg-muted p-4 rounded-lg"
          >
            <h3 className="font-medium mb-2">Siz:</h3>
            <p className="text-sm">{transcript}</p>
          </motion.div>
        )}

        {/* AI YanÄ±tÄ± */}
        {aiResponse && (
          <motion.div
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            className="bg-primary/10 p-4 rounded-lg"
          >
            <h3 className="font-medium mb-2">AI Ã–ÄŸretmen:</h3>
            <p className="text-sm">{aiResponse}</p>
          </motion.div>
        )}

                 {/* Talimatlar */}
         <div className="text-center text-sm text-muted-foreground">
           <p>ğŸŒ Dil seÃ§in (Ä°ngilizce/TÃ¼rkÃ§e)</p>
           <p>ğŸ”„ SÃ¼rekli dinleme modu aktif</p>
           <p>ğŸ¤ Mikrofon butonuna basÄ±n ve konuÅŸun</p>
           <p>âš¡ GerÃ§ek zamanlÄ± stream yanÄ±tlarÄ±</p>
           <p>ğŸ”Š AI Ä°ngilizce olarak yanÄ±t verecek</p>
           <p>ğŸ’¬ Google AI Studio benzeri deneyim</p>
         </div>
      </div>
    </div>
  );
}
